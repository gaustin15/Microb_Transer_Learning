{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_abundance_data, load_markers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training_functions import tune_VAE, tune_SAE, tune_DAE, tune_RF, tune_SVM, tune_FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_abundance_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 15:57:40] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 15:57:40] ax.service.managed_loop: Started full optimization with 8 steps.\n",
      "[INFO 03-27 15:57:40] ax.service.managed_loop: Running optimization trial 1...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 15:57:44] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 15:57:44] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 15:57:45] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 15:57:45] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 15:57:45] ax.service.managed_loop: Running optimization trial 2...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 15:57:46] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 15:57:46] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 15:57:46] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 15:57:49] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 15:57:50] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 15:57:55] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 15:58:02] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 15:58:08] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 15:58:15] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 15:58:21] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 15:58:23] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 15:58:29] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 15:58:37] ax.service.managed_loop: Running optimization trial 3...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 15:58:50] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 15:58:50] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 15:58:50] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 15:58:51] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 15:58:56] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 15:59:02] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 15:59:03] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 15:59:07] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 15:59:14] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 15:59:21] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 15:59:29] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 15:59:30] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 15:59:40] ax.service.managed_loop: Running optimization trial 4...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 15:59:48] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 15:59:48] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 15:59:48] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 15:59:49] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 15:59:49] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 15:59:50] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 15:59:51] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 15:59:51] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 15:59:52] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 15:59:52] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 15:59:53] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 15:59:53] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 15:59:54] ax.service.managed_loop: Running optimization trial 5...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 16:00:02] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 16:00:02] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 16:00:02] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 16:00:03] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 16:00:03] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 16:00:03] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 16:00:03] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 16:00:03] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 16:00:03] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 16:00:03] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 16:00:04] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 16:00:04] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 16:00:04] ax.service.managed_loop: Running optimization trial 6...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 16:00:05] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 16:00:05] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 16:00:05] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 16:00:11] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 16:00:16] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 16:00:20] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 16:00:27] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 16:00:34] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 16:00:38] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 16:00:49] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 16:00:51] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 16:00:54] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 16:00:59] ax.service.managed_loop: Running optimization trial 7...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 16:01:02] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 16:01:02] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 16:01:02] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 16:01:03] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 16:01:14] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 16:01:23] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 16:01:29] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 16:01:37] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 16:01:44] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 16:01:49] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 16:01:51] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 16:01:54] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 16:02:04] ax.service.managed_loop: Running optimization trial 8...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 16:02:09] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 16:02:09] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 16:02:09] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 16:02:10] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 16:02:10] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 16:02:10] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 16:02:10] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 16:02:10] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 16:02:11] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 16:02:11] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 16:02:11] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 16:02:11] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    }
   ],
   "source": [
    "model_results = tune_SAE(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 17:14:55] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:14:55] ax.service.managed_loop: Started full optimization with 8 steps.\n",
      "[INFO 03-27 17:14:55] ax.service.managed_loop: Running optimization trial 1...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 17:15:01] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:15:01] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:15:01] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:15:05] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:15:06] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:15:10] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:15:11] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:15:22] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:15:33] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:15:35] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:15:43] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:15:51] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:16:02] ax.service.managed_loop: Running optimization trial 2...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 17:16:06] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:16:06] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:16:06] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:16:10] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:16:14] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:16:17] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:16:25] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:16:29] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:16:32] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:16:33] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:16:42] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:16:45] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:16:47] ax.service.managed_loop: Running optimization trial 3...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 17:16:48] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:16:48] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:16:48] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:16:51] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:16:52] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:16:54] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:16:58] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:17:04] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:17:09] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:17:10] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:17:11] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:17:12] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:17:19] ax.service.managed_loop: Running optimization trial 4...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 17:17:22] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:17:22] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:17:22] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:17:29] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:17:29] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:17:32] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:17:38] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:17:43] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:17:48] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:17:51] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:17:59] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:18:02] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:18:07] ax.service.managed_loop: Running optimization trial 5...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 17:18:15] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:18:15] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:18:15] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:18:23] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:18:31] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:18:32] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:18:33] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:18:34] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:18:40] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:18:43] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:18:49] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:18:52] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:19:00] ax.service.managed_loop: Running optimization trial 6...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 17:19:02] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:19:02] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:19:02] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:19:07] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:19:12] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:19:17] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:19:18] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:19:19] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:19:28] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:19:35] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:19:36] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:19:37] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:19:39] ax.service.managed_loop: Running optimization trial 7...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 17:19:40] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:19:40] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:19:40] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:19:40] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:19:47] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:19:49] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:19:55] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:20:00] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:20:04] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:20:11] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:20:14] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:20:15] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:20:18] ax.service.managed_loop: Running optimization trial 8...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 17:20:20] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:20:20] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 17:20:20] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:20:20] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:20:20] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:20:20] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:20:20] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:20:21] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:20:21] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:20:21] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:20:21] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:20:22] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    }
   ],
   "source": [
    "dae_results=tune_DAE(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 20:00:57] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:00:57] ax.service.managed_loop: Started full optimization with 8 steps.\n",
      "[INFO 03-27 20:00:57] ax.service.managed_loop: Running optimization trial 1...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:01:01] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:01:01] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:01:01] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:01:01] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:01:01] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:01:01] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:01:02] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:01:02] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:01:02] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:01:02] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:01:02] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:01:02] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 20:01:02] ax.service.managed_loop: Running optimization trial 2...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:01:05] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:01:05] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:01:05] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:01:05] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:01:05] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:01:05] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:01:06] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:01:06] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:01:06] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:01:06] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:01:06] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:01:06] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 20:01:06] ax.service.managed_loop: Running optimization trial 3...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:01:10] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 20:01:10] ax.service.managed_loop: Running optimization trial 4...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 20:01:14] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 20:01:14] ax.service.managed_loop: Running optimization trial 5...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:01:17] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:01:17] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:01:17] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 20:01:18] ax.service.managed_loop: Running optimization trial 6...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:01:21] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:01:21] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 20:01:22] ax.service.managed_loop: Running optimization trial 7...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:01:25] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:01:25] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:01:25] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:01:29] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:01:35] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:01:38] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:01:39] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:01:44] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:01:50] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:01:54] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:01:55] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:01:55] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 20:01:58] ax.service.managed_loop: Running optimization trial 8...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 20:02:00] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:02:00] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-27 20:02:00] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 20:02:00] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 20:02:00] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 20:02:00] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 20:02:00] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 20:02:01] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 20:02:01] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 20:02:01] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 20:02:01] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 20:02:01] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    }
   ],
   "source": [
    "vae_results=tune_VAE(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 20:56:41] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 20:56:41] ax.service.managed_loop: Started full optimization with 8 steps.\n",
      "[INFO 03-27 20:56:41] ax.service.managed_loop: Running optimization trial 1...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:56:46] ax.service.managed_loop: Running optimization trial 2...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:56:48] ax.service.managed_loop: Running optimization trial 3...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:56:53] ax.service.managed_loop: Running optimization trial 4...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:56:56] ax.service.managed_loop: Running optimization trial 5...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:56:59] ax.service.managed_loop: Running optimization trial 6...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:57:02] ax.service.managed_loop: Running optimization trial 7...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "[INFO 03-27 20:57:04] ax.service.managed_loop: Running optimization trial 8...\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ffnn_results = tune_FFNN(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abundance',\n",
       " 'Quin_gut_liver_cirrhosis',\n",
       " {'layer_1_size': 512,\n",
       "  'layer_2_size': 64,\n",
       "  'layer_3_size': 128,\n",
       "  'learning_rate': 0.01,\n",
       "  'dropout': 0.5},\n",
       " ({'objective': 0.8514492753623188}, {'objective': {'objective': 0.0}})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abundance',\n",
       " 'Quin_gut_liver_cirrhosis',\n",
       " {'layer_1_size': 256, 'layer_2_size': 8, 'classifier_model': 'svm'},\n",
       " ({'objective': 0.8985507246376813}, {'objective': {'objective': 0.0}})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 17:57:03] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:57:03] ax.service.managed_loop: Started full optimization with 15 steps.\n",
      "[INFO 03-27 17:57:03] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:57:05] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:57:08] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:57:13] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:57:13] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:57:17] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:57:22] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:57:24] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:57:25] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:57:30] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:57:33] ax.service.managed_loop: Running optimization trial 11...\n",
      "[INFO 03-27 17:57:38] ax.service.managed_loop: Running optimization trial 12...\n",
      "[INFO 03-27 17:57:39] ax.service.managed_loop: Running optimization trial 13...\n",
      "[INFO 03-27 17:57:45] ax.service.managed_loop: Running optimization trial 14...\n",
      "[INFO 03-27 17:57:51] ax.service.managed_loop: Running optimization trial 15...\n"
     ]
    }
   ],
   "source": [
    "rf_results=tune_RF(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abundance',\n",
       " 'Quin_gut_liver_cirrhosis',\n",
       " {'n_estimators': 100, 'min_samples_leaf': 2, 'criterion': 'gini'},\n",
       " 0.9347826086956523]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-27 17:58:46] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-27 17:58:46] ax.service.managed_loop: Started full optimization with 15 steps.\n",
      "[INFO 03-27 17:58:46] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-27 17:58:46] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-27 17:58:46] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-27 17:58:47] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-27 17:58:47] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-27 17:58:48] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-27 17:58:48] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-27 17:58:48] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-27 17:58:49] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-27 17:58:49] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-27 17:58:50] ax.service.managed_loop: Running optimization trial 11...\n",
      "[INFO 03-27 17:58:50] ax.service.managed_loop: Running optimization trial 12...\n",
      "[INFO 03-27 17:58:50] ax.service.managed_loop: Running optimization trial 13...\n",
      "[INFO 03-27 17:58:51] ax.service.managed_loop: Running optimization trial 14...\n",
      "[INFO 03-27 17:58:51] ax.service.managed_loop: Running optimization trial 15...\n"
     ]
    }
   ],
   "source": [
    "svm_results=tune_SVM(dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abundance',\n",
       " 'Quin_gut_liver_cirrhosis',\n",
       " {'C': 3, 'gamma': -9},\n",
       " 0.7318840579710144]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abundance',\n",
       " 'Quin_gut_liver_cirrhosis',\n",
       " {'layer_1_size': 256, 'layer_2_size': 512, 'classifier_model': 'rf'},\n",
       " ({'objective': 0.8949275362318841}, {'objective': {'objective': 0.0}})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dae_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abundance',\n",
       " 'Quin_gut_liver_cirrhosis',\n",
       " {'layer_size': 256, 'classifier_model': 'rf'},\n",
       " ({'objective': 0.9021739130434783}, {'objective': {'objective': 0.0}})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning:\n",
      "\n",
      "Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning:\n",
      "\n",
      "Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning:\n",
      "\n",
      "Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning:\n",
      "\n",
      "Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning:\n",
      "\n",
      "Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning:\n",
      "\n",
      "Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markers = load_markers_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "dnabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
