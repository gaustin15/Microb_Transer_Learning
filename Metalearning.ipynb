{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need older version of lightning for this notebook to run\n",
    "\n",
    "import sys\n",
    "sys.path.append('learn2learn/') # the version on pypi doesn't have LightningMAML\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "\n",
    "import learn2learn as l2l\n",
    "from learn2learn.data import TaskDataset\n",
    "from learn2learn.algorithms.lightning import LightningMAML\n",
    "from learn2learn.utils.lightning import EpisodicBatcher\n",
    "\n",
    "from baseline.pytorch_models import LitFFNN\n",
    "from baseline.training_functions import *\n",
    "from baseline.training_functions import make_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from datasets import load_abundance_data, get_shared_taxa_dfs\n",
    "from datasets import MicroDataset, Dataset\n",
    "import torch.nn.functional as F\n",
    "dfs = load_abundance_data()\n",
    "all_datasets = get_shared_taxa_dfs(dfs)\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Abundance</td>\n",
       "      <td>Quin_gut_liver_cirrhosis</td>\n",
       "      <td>[1024, 128, 128, 0.1, 0.5]</td>\n",
       "      <td>0.746377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Abundance</td>\n",
       "      <td>WT2D</td>\n",
       "      <td>[128, 64, 32, 0.001, 0.5]</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Abundance</td>\n",
       "      <td>Zeller_fecal_colorectal_cancer</td>\n",
       "      <td>[256, 256, 32, 0.1, 0.1]</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Abundance</td>\n",
       "      <td>Chatelier_gut_obesity</td>\n",
       "      <td>[1024, 128, 32, 0.01, 0.1]</td>\n",
       "      <td>0.690311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Abundance</td>\n",
       "      <td>metahit</td>\n",
       "      <td>[1024, 64, 128, 0.1, 0.5]</td>\n",
       "      <td>0.623529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Abundance</td>\n",
       "      <td>t2dmeta_long</td>\n",
       "      <td>[256, 256, 128, 0.1, 0.1]</td>\n",
       "      <td>0.605882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Type  Data Type                         Dataset  \\\n",
       "0       FFNN  Abundance        Quin_gut_liver_cirrhosis   \n",
       "1       FFNN  Abundance                            WT2D   \n",
       "2       FFNN  Abundance  Zeller_fecal_colorectal_cancer   \n",
       "3       FFNN  Abundance           Chatelier_gut_obesity   \n",
       "4       FFNN  Abundance                         metahit   \n",
       "5       FFNN  Abundance                    t2dmeta_long   \n",
       "\n",
       "                  hyperparams       AUC  \n",
       "0  [1024, 128, 128, 0.1, 0.5]  0.746377  \n",
       "1   [128, 64, 32, 0.001, 0.5]  0.595960  \n",
       "2    [256, 256, 32, 0.1, 0.1]  0.700000  \n",
       "3  [1024, 128, 32, 0.01, 0.1]  0.690311  \n",
       "4   [1024, 64, 128, 0.1, 0.5]  0.623529  \n",
       "5   [256, 256, 128, 0.1, 0.1]  0.605882  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('results/baseline/ffnn_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [b for a,b in all_datasets.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [make_split(df) for df in datasets]\n",
    "\n",
    "#redo the split for the dataset of interest (the one at idx 0)\n",
    "# so we include a test set\n",
    "train, test = make_split(datasets[0])\n",
    "train, valid = make_split(train)\n",
    "\n",
    "splits[0] = (train, valid)\n",
    "\n",
    "trains = pd.concat( [s[0] for s in splits], axis=0 ).reset_index(drop=True)\n",
    "vals = pd.concat( [s[1] for s in splits], axis=0 ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaMicroDataset(Dataset):\n",
    "    \"\"\"Dataset class for column dataset.\n",
    "    Args:\n",
    "       cats (list of str): List of the name of columns contain\n",
    "                           categorical variables.\n",
    "       conts (list of str): List of the name of columns which \n",
    "                           contain continuous variables.\n",
    "       y (Tensor, optional): Target variables.\n",
    "       is_reg (bool): If the task is regression, set ``True``, \n",
    "                      otherwise (classification) ``False``.\n",
    "       is_multi (bool): If the task is multi-label classification, \n",
    "                        set ``True``.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, is_marker = False):\n",
    "        df = df.sample(frac=1)\n",
    "        if not is_marker:\n",
    "            self.taxa_cols = df.columns[df.columns.str.contains('k__')] \n",
    "        else:\n",
    "            self.taxa_cols = df.columns[df.columns.str.contains('gi[|]')] \n",
    "        self.matrix = torch.Tensor( df[self.taxa_cols].astype(float).values ).float()\n",
    "        \n",
    "        #scale the dataset to be in relative abundance space\n",
    "        self.matrix=F.softmax(self.matrix, requires_grad=True)\n",
    "        \n",
    "        df.loc[df.disease=='ibd_crohn_disease'] = 'ibd_ulcerative_colitis'\n",
    "        self.y=torch.Tensor( pd.Categorical(df.disease).codes ).long()\n",
    "        self.n_samples, self.n_taxa= self.matrix.shape\n",
    "        \n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.matrix[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(a):\n",
    "    \"\"\"\n",
    "    collate function to simplify the tasks -- only want to ever distinguish between class 0 and 1\n",
    "    Each class can represent any positive/negative group from any dataset\n",
    "    6 datasets ==> 12 classes ==> 132 distinct metalearning tasks\n",
    "    \"\"\"\n",
    "    idx = max([b[1] for b in a])\n",
    "    #print(a[1])\n",
    "    return(torch.cat( [b[0].unsqueeze(0) for b in a] ),\n",
    "           torch.Tensor( [int(b[1]==idx)  for b in a]) )#.long() )\n",
    "\n",
    "def collate(a):\n",
    "    \"\"\"\n",
    "    collate function to simplify the tasks -- only want to ever distinguish between class 0 and 1\n",
    "    Each class can represent any positive/negative group from any dataset\n",
    "    6 datasets ==> 12 classes ==> 132 distinct metalearning tasks\n",
    "    \"\"\"\n",
    "    #idx = max([b[1] for b in a])\n",
    "    q = torch.Tensor([b[1] for b in a])\n",
    "    return(torch.cat( [b[0].unsqueeze(0) for b in a] ),\n",
    "           ( q == q.max() ).long() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_taskset(datasets):\n",
    "    MetaDS = l2l.data.UnionMetaDataset( [l2l.data.MetaDataset( MicroDataset(t) ) for t in datasets] )\n",
    "    dataset = l2l.data.MetaDataset(MetaDS)\n",
    "    transforms = [\n",
    "        l2l.data.transforms.NWays(dataset, n=2),\n",
    "        l2l.data.transforms.KShots(dataset, k=5),\n",
    "        l2l.data.transforms.LoadData(dataset)\n",
    "    ]\n",
    "    return( TaskDataset(dataset, transforms, num_tasks=10, task_collate=collate) )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.1 ms, sys: 2.62 ms, total: 69.8 ms\n",
      "Wall time: 65.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# MetaDS = MetaMicroDataset(trains)\n",
    "MetaDS = l2l.data.UnionMetaDataset( [l2l.data.MetaDataset( MicroDataset(t) ) for t in datasets] )\n",
    "dataset = l2l.data.MetaDataset(MetaDS)\n",
    "transforms = [\n",
    "    l2l.data.transforms.NWays(dataset, n=2),\n",
    "    l2l.data.transforms.KShots(dataset, k=5),\n",
    "    l2l.data.transforms.LoadData(dataset)\n",
    "]\n",
    "train_set = TaskDataset(dataset, transforms, num_tasks=10, task_collate=collate)\n",
    "for task in taskset:\n",
    "    X, y = task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    a deep FFNN network -- assuming it's going to show improvements\n",
    "    in the transfer learning exploration\n",
    "    probably won't be so good in standard learning approach\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 dataset, \n",
    "                 layer_sizes = [128, 64, 32], \n",
    "                 dropout = .2, \n",
    "                 n_labels = 2):\n",
    "        super(FFNN, self).__init__()\n",
    "        \n",
    "        linear_layers = [ nn.Linear( dataset.n_taxa, layer_sizes[0]), \n",
    "                          nn.BatchNorm1d(layer_sizes[0]), \n",
    "                          nn.Dropout(dropout), \n",
    "                          nn.GELU()]\n",
    "        self.n_labels=n_labels\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            linear_layers += [ nn.Linear(layer_sizes[i], layer_sizes[i+1]), \n",
    "                               nn.BatchNorm1d(layer_sizes[i+1]), \n",
    "                               nn.Dropout(dropout), \n",
    "                               nn.GELU()]\n",
    "            \n",
    "        linear_layers += [ nn.Linear(layer_sizes[-1], n_labels), \n",
    "                           nn.Softmax() ]\n",
    "        \n",
    "        self.linear_net = nn.Sequential(*linear_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear_net(x.float())\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maml.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Desktop/MLFG_Project/datasets.py:32: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning:\n",
      "\n",
      "Checkpoint directory checkpoint_dir exists and is not empty with save_top_k=1 All files in this directory will be deleted when a checkpoint is saved!\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "   | Name                       | Type             | Params\n",
      "-----------------------------------------------------------------\n",
      "0  | loss                       | CrossEntropyLoss | 0     \n",
      "1  | model                      | MAML             | 109 K \n",
      "2  | model.module               | FFNN             | 109 K \n",
      "3  | model.module.linear_net    | Sequential       | 109 K \n",
      "4  | model.module.linear_net.0  | Linear           | 98 K  \n",
      "5  | model.module.linear_net.1  | BatchNorm1d      | 256   \n",
      "6  | model.module.linear_net.2  | Dropout          | 0     \n",
      "7  | model.module.linear_net.3  | GELU             | 0     \n",
      "8  | model.module.linear_net.4  | Linear           | 8 K   \n",
      "9  | model.module.linear_net.5  | BatchNorm1d      | 128   \n",
      "10 | model.module.linear_net.6  | Dropout          | 0     \n",
      "11 | model.module.linear_net.7  | GELU             | 0     \n",
      "12 | model.module.linear_net.8  | Linear           | 2 K   \n",
      "13 | model.module.linear_net.9  | BatchNorm1d      | 64    \n",
      "14 | model.module.linear_net.10 | Dropout          | 0     \n",
      "15 | model.module.linear_net.11 | GELU             | 0     \n",
      "16 | model.module.linear_net.12 | Linear           | 66    \n",
      "17 | model.module.linear_net.13 | Softmax          | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74209e915ac41d7bfb7555da36f3c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/container.py:117: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f2a67496354e43a98885a0cef29581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3b7ad52bb04782b0c18c9436cd2ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3244473767c341e488e2bf8e87841f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f361d7b8fb4048810b4a17cf5dbf27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b728acd2f6ab43b2aca4d5bcfdb7672f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d47cf4188dd425db080b358d8c484f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c0c40c9c3e4af78060935996556a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27747f513234473b5fe443a4de04c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67ab45f162246be97578273af8766f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9c6c8af7b14935ad805cca1946473b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4eeb068ff2c444882ec4d885d8b36f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76308fe1ded041caa543a374ee764cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08beba0017964dc5860ca8a7006b4d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a61a2b026dc48cfbc801fb45c8b0637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f43c1887b3b4f3bb12972ce667d8a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c59359e4e44183a8983a012137503c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f03846ca5d418ba2edfc04da508dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5634e0a09a4403cb93a912ca814b7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22000c2a497480da04cbc0d8e2cdc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17696652858430989989b8e0e4c9442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e794066cd9414914a11cd9107c8f31b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4027dbf841e841d7b9fd034521ead974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33409a983dd74d25aca9b1248ef8fe57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf1c436b63945cd8bd5f5d7c161d5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e31b170f1f6479bb350ae059e32824a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1445f8e2b79343eea4b9e638631afd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11b45abd56c4253bee3f34fab67a403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78e71caa507455aa259226ecd5bfbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdea62cc35542959286b637ecc75812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09d3ee46db748538bcec1dc8e641227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80853af0f3a84514ad6eed435ff5df26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ca35a966494be3a97c3d4c9a25b569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204ee4d0efa54d3f80bf37bf05e3aa2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6fc48684b244788fe0e4e80aac525b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c3939dd8ec4e2aaf1a42a526bade2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975a9b2bc1594dd1b025d10177e9e2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc87ffcb90543ea86b670b69ab067e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e26981532b42609648dfcb0cb56eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f5c82185ba455cbdd7a3efe873d51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f723e2fbcfe844f9b3cc46a078b040ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7f1ddd424e4a3fb3b59fb35f6beaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdd03f32c50422fb355637ebf9004c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09424b477ae47f9b9d87d5955bfe4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f49a9d7996e4f529438754a2ba8a9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60155a13f34f4f0593b6048c6195de7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52738b43d43a4e16a7b04d11eacec801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba2dda5bb6640c88c43b54fd45bbd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051582c380f34116ab780f46da0f22a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1491b7f912da4af5a486531368f0b8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f892fd87e494b2dbdc2dc1cf54405e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c53b1dcf3f249e39b80d9b29de989dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ef29b927c141af9015bb62965a9218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0714c6f92e401f9d57e64ed1e3d4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32830ead4db4d488827a4834dbb4876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe13ee3719843a7ac019b6ea815f5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b541797e2a4b4f25981835b705c76b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6f252696d94bd5aa20a9d4e21c06f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566280d7bf854a7f958c33b17cdca30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fbd5cf695b4a2db892c1b8d9cf2e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014c3373ec7a4e348f22cfc526019f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bf86a2426d4dc78ad08db958681e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/anaconda2/envs/dnabert/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning:\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FFNN(dataset=MicroDataset(trains))\n",
    "maml = LightningMAML(model, adaptation_lr=0.1, lr = .002)#, loss=torch.nn.MSELoss())\n",
    "# , allow_nograd=True, \n",
    "#                     allow_unused=True)\n",
    "episodic_data = EpisodicBatcher(taskset, taskset)#, taskset)\n",
    "#EpisodicBatcher(tasksets.train, tasksets.validation, tasksets.test)\n",
    "\n",
    "#setr up the trainer/logger/callbacks\n",
    "checkpoint_callback=ModelCheckpoint(\n",
    "                filepath = 'checkpoint_dir',\n",
    "                save_top_k=1,\n",
    "                verbose=False,\n",
    "                monitor='valid_loss',\n",
    "                mode='min'\n",
    "                )\n",
    "\n",
    "tube_logger = TestTubeLogger('checkpoint_dir', \n",
    "                            name='test_tube_logger')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs = 1000,\n",
    "#              num_sanity_val_steps=0,\n",
    "             progress_bar_refresh_rate=1,\n",
    "             weights_summary='full',\n",
    "             check_val_every_n_epoch=1,\n",
    "             checkpoint_callback=checkpoint_callback,\n",
    "            callbacks=[EarlyStopping(monitor='valid_loss', \n",
    "                                    patience=50)]) \n",
    "\n",
    "trainer.fit(maml, episodic_data)\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqq=torch.load(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Desktop/MLFG_Project/datasets.py:32: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load best_model_path's params\n",
    "maml.load_state_dict(torch.load(checkpoint_callback.best_model_path)['state_dict'])\n",
    "\n",
    "#set up standard model ==> for lightning training\n",
    "lightning = LitFFNN(train, \n",
    "                    valid)\n",
    "lightning.model.load_state_dict(maml.model.module.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Desktop/MLFG_Project/datasets.py:32: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback.best_model_score\n",
    "lightning = LitFFNN(train, \n",
    "                    valid)\n",
    "lightning.model.load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Trainer(max_epochs = 100,\n",
    "             logger=tube_logger,\n",
    "             progress_bar_refresh_rate=0,\n",
    "             weights_summary=None,\n",
    "             check_val_every_n_epoch=1,\n",
    "             checkpoint_callback=checkpoint_callback,\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                    patience=20)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaDS = MetaMicroDataset(vals)\n",
    "dataset = l2l.data.MetaDataset(MetaDS)\n",
    "# transforms = [\n",
    "#     l2l.data.transforms.NWays(dataset, n=5),\n",
    "#     l2l.data.transforms.KShots(dataset, k=1),\n",
    "#     l2l.data.transforms.LoadData(dataset),\n",
    "# ]\n",
    "# val_taskset = TaskDataset(dataset, transforms, num_tasks=20)\n",
    "# for task in val_taskset:\n",
    "#     X, y = task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taskset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline.training_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Example for running few-shot algorithms with the PyTorch Lightning wrappers.\n",
    "\"\"\"\n",
    "\n",
    "import learn2learn as l2l\n",
    "import pytorch_lightning as pl\n",
    "from argparse import ArgumentParser\n",
    "from learn2learn.algorithms import (\n",
    "    LightningPrototypicalNetworks,\n",
    "    LightningMetaOptNet,\n",
    "    LightningMAML,\n",
    "    LightningANIL,\n",
    ")\n",
    "from learn2learn.utils.lightning import EpisodicBatcher\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = ArgumentParser(conflict_handler=\"resolve\", add_help=True)\n",
    "    # add model and trainer specific args\n",
    "    parser = LightningPrototypicalNetworks.add_model_specific_args(parser)\n",
    "    parser = LightningMetaOptNet.add_model_specific_args(parser)\n",
    "    parser = LightningMAML.add_model_specific_args(parser)\n",
    "    parser = LightningANIL.add_model_specific_args(parser)\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # add script-specific args\n",
    "    parser.add_argument(\"--algorithm\", type=str, default=\"protonet\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default=\"mini-imagenet\")\n",
    "    parser.add_argument(\"--root\", type=str, default=\"~/data\")\n",
    "    parser.add_argument(\"--meta_batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    return(parser)\n",
    "    args = parser.parse_args()\n",
    "    dict_args = vars(args)\n",
    "\n",
    "    pl.seed_everything(args.seed)\n",
    "    print('hi')\n",
    "    print(args)\n",
    "    # Create tasksets using the benchmark interface\n",
    "    if False and args.dataset in [\"mini-imagenet\", \"tiered-imagenet\"]:\n",
    "        data_augmentation = \"lee2019\"\n",
    "    else:\n",
    "        data_augmentation = \"normalize\"\n",
    "    tasksets = l2l.vision.benchmarks.get_tasksets(\n",
    "        name=args.dataset,\n",
    "        train_samples=args.train_queries + args.train_shots,\n",
    "        train_ways=args.train_ways,\n",
    "        test_samples=args.test_queries + args.test_shots,\n",
    "        test_ways=args.test_ways,\n",
    "        root=args.root,\n",
    "        data_augmentation=data_augmentation,\n",
    "    )\n",
    "    episodic_data = EpisodicBatcher(\n",
    "        tasksets.train,\n",
    "        tasksets.validation,\n",
    "        tasksets.test,\n",
    "        epoch_length=args.meta_batch_size * 10,\n",
    "    )\n",
    "\n",
    "    # init model\n",
    "    if args.dataset in [\"mini-imagenet\", \"tiered-imagenet\"]:\n",
    "        model = l2l.vision.models.ResNet12(output_size=args.train_ways)\n",
    "    else:  # CIFAR-FS, FC100\n",
    "        model = l2l.vision.models.CNN4(\n",
    "            output_size=args.train_ways,\n",
    "            hidden_size=64,\n",
    "            embedding_size=64*4,\n",
    "        )\n",
    "    features = model.features\n",
    "    classifier = model.classifier\n",
    "\n",
    "    # init algorithm\n",
    "    if args.algorithm == \"protonet\":\n",
    "        algorithm = LightningPrototypicalNetworks(features=features, **dict_args)\n",
    "    elif args.algorithm == \"maml\":\n",
    "        algorithm = LightningMAML(model, **dict_args)\n",
    "    elif args.algorithm == \"anil\":\n",
    "        algorithm = LightningANIL(features, classifier, **dict_args)\n",
    "    elif args.algorithm == \"metaoptnet\":\n",
    "        algorithm = LightningMetaOptNet(features, **dict_args)\n",
    "\n",
    "    trainer = pl.Trainer.from_argparse_args(\n",
    "        args,\n",
    "        gpus=1,\n",
    "        accumulate_grad_batches=args.meta_batch_size,\n",
    "        callbacks=[\n",
    "            l2l.utils.lightning.TrackTestAccuracyCallback(),\n",
    "            l2l.utils.lightning.NoLeaveProgressBar(),\n",
    "        ],\n",
    "    )\n",
    "    trainer.fit(model=algorithm, datamodule=episodic_data)\n",
    "    trainer.test(ckpt_path=\"best\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser(conflict_handler=\"resolve\", add_help=True)\n",
    "# add model and trainer specific args\n",
    "# parser = LightningPrototypicalNetworks.add_model_specific_args(parser)\n",
    "# parser = LightningMetaOptNet.add_model_specific_args(parser)\n",
    "# parser = LightningMAML.add_model_specific_args(parser)\n",
    "# # parser = LightningANIL.add_model_specific_args(parser)\n",
    "# # parser = pl.Trainer.add_argparse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning = LitFFNN(trains, \n",
    "                    vals, \n",
    "                    layer_1_dim = 256,#hyperparams['layer_1_size'],\n",
    "                    layer_2_dim = 256,#, hyperparams['layer_2_size'],\n",
    "                    layer_3_dim = 32, #hyperparams['layer_3_size'],\n",
    "                    learning_rate = .1,#hyperparams['learning_rate'],\n",
    "                    batch_size=50, \n",
    "                    dropout=.2#hyperparams['dropout']\n",
    "                    )\n",
    "\n",
    "#setr up the trainer/logger/callbacks\n",
    "checkpoint_callback=ModelCheckpoint(\n",
    "                dirpath = 'checkpoint_dir',\n",
    "                save_top_k=1,\n",
    "                verbose=False,\n",
    "                monitor='val_loss',\n",
    "                mode='min'\n",
    "                )\n",
    "\n",
    "tube_logger = TestTubeLogger('checkpoint_dir', \n",
    "                            name='test_tube_logger')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs = 500,\n",
    "                     logger=tube_logger,\n",
    "                     progress_bar_refresh_rate=0,\n",
    "                     weights_summary=None,\n",
    "                     check_val_every_n_epoch=1,\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                            patience=20)]) #the patience of 20 is mentioned in the DeepMicro paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qqq = LightningMAML(lightning.model, loss = torch.nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from learn2learn.data import MetaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLitFFNN(LitFFNN):\n",
    "    \n",
    "    def init_MAML_loss(self, ...):\n",
    "        lr=0.001\n",
    "        maml_lr=0.0005\n",
    "        #iterations=1000\n",
    "        ways=2\n",
    "        shots=1\n",
    "        # tps=16\n",
    "        tps = 5\n",
    "\n",
    "        fas=3\n",
    "        mu = 1\n",
    "\n",
    "        model = CompleteMHAPacking(proc_field, visit_field, emb_dim = 64,\n",
    "                                   hidden_size = 32, head_count = 2, dropout = .3)\n",
    "        model.to(device)\n",
    "\n",
    "        meta_model = l2l.algorithms.MAML(model, lr=maml_lr)\n",
    "        opt = optim.AdamW(meta_model.parameters(), lr=lr)\n",
    "\n",
    "        #loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "        # bias = np.log( ( np.array(ny) / np.max(np.array(ny)) ))\n",
    "        # linear = model.linear.state_dict()\n",
    "        # linear['bias'] = torch.tensor( bias )\n",
    "        # model.linear.load_state_dict(linear)\n",
    "\n",
    "\n",
    "        lr = 0.001\n",
    "        #  ClassBalancedFocalLoss(.95, 2), (.95, 5) also gave similarly poor results\n",
    "        #  (please tell me if im setting up this loss function incorrectly)\n",
    "\n",
    "\n",
    "        # ==> focus on Classbalanced\n",
    "        # loss_func = ClassBalancedFocalLoss(.95, ny, 2)\n",
    "        # loss_func.to(device)\n",
    "\n",
    "        loss_func = nn.BCELoss()\n",
    "\n",
    "\n",
    "        #we have 4 tasks to meta-learn from\n",
    "        # most published approaches would not use the RA data in the metalearning step\n",
    "        #                         --> this doesn't make sense to me for this context\n",
    "        #              --> it makes more sense if we are stricly isolating how much carryover information we can get\n",
    "        #   --> to get best results i don't see why eliminating RA is necessary, but this is an easy thing to change in the future\n",
    "        num_tasks = 4\n",
    "\n",
    "        #determine number of datapoints to sample at each iteration\n",
    "        #samp_size = 100\n",
    "        iterations = 500\n",
    "    with torch.backends.cudnn.flags(enabled=False):\n",
    "        for iteration in range(iterations):\n",
    "\n",
    "            for _ in tqdm.tqdm( range(tps) ):\n",
    "                learner = self.model.clone( allow_unused=True )\n",
    "\n",
    "                #get data from a randomly selected task\n",
    "                        #for the 'experiment' currently only looking at source tasks for the metalearning\n",
    "                task = all_tasks[np.random.choice(4, 1)[0]]\n",
    "\n",
    "                for step in range(fas):\n",
    "                    # Compute validation loss\n",
    "                    learner.zero_grad()\n",
    "                    batch = next(task)\n",
    "                    preds = learner(batch)\n",
    "                    loss = loss_func(preds, to_categorical(batch.ird) )\n",
    "                    learner.adapt(loss)\n",
    "                    del batch, preds, loss\n",
    "\n",
    "                batch = get_batch(task)\n",
    "\n",
    "                source_loss = loss_func( learner(batch, device), to_categorical( batch.ird ) )\n",
    "\n",
    "                batch = next( all_tasks[0].__iter__() )\n",
    "                #get the loss with the fas-updated learner\n",
    "                preds = learner(batch, device)       \n",
    "\n",
    "                # Take the meta-learning step\n",
    "                opt.zero_grad()\n",
    "                val_error = loss_func(preds, to_categorical(batch.ird) ) #torch.as_tensor(batch.ird).long() )\n",
    "                #val_error.backward()\n",
    "\n",
    "                meta_pred_loss = val_error + mu * source_loss\n",
    "                meta_pred_loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                del batch, preds, val_error, learner\n",
    "\n",
    "            if iteration%5 == 0:\n",
    "                print(iteration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "dnabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
